# Redis를 캐시로 이용하기

캐시는 아래와 같은 조건에서 성능을 효과적으로 개선할 수 있습니다.

- **원본 데이터 저장소에서 검색하는 시간이 오래 걸리거나**, 매번 계산을 통해서 데이터를 가져와야 한다.
- **캐시에서 데이터를 가져오는 것이 원본 데이터 저장소 데이터를 요청하는 것보다 빨라야** 한다.
- **캐시에 저장된 데이터는 잘 변하지 않는 데이터**이다.
- **캐시에 저장된 데이터는 자주 검색되는 데이터**이다.

## **캐싱 전략**

### **읽기전략 - Look Aside (Cache-Aside)**

찾고자 하는 데이터가 먼저 캐시에 있는지 확인한 뒤, 캐시에 데이터가 있으면 캐시에서 데이터를 읽어옵니다.

이를 **캐시 히트(Cache Hit)라** 합니다.

찾고자 하는 데이터가 없을 때에는 **캐시 미스(Cache Miss)가** 발생하며 아래와 같은 과정을 거칩니다.

![cache-miss-image](https://image.toast.com/aaaadh/real/2020/techblog/1%2810%29.png)

**장점:**
- Redis에 문제가 생겨 접근을 할 수 없더라도 바로 서비스 장애로 이어지지 않고 데이터베이스에서 데이터를 가져올 수 있습니다.

**단점:**
- 기존에 애플리케이션에서 Redis를 통해 데이터를 가져오는 연결이 매우 많았다면 모든 커넥션이 한꺼번에 원본 데이터베이스로 몰려 많은 부하를 발생시킬 수 있습니다.

이러한 구조를 **Lazy Loading**이라고 부릅니다.

만약 기존 서비스에 Redis를 투입하거나 데이터베이스에만 새로운 데이터를 저장한다면 애플리케이션은 데이터를 찾기 위해서 Redis에 매번 먼저 접근할 것이고 그때마다 캐시 미스가 일어나 데이터베이스와 Redis에 재접근하는 과정을 통해 지연이 초래되어 성능에 영향을 줄 수 있습니다.

따라서 이러한 상황에서는 미리 데이터베이스에서 캐시로 데이터를 밀어넣어주는 작업을 하기도 합니다. 이를 **캐시 워밍(Cache Warming)** 이라고 합니다.

### **캐시 일관성 전략**

캐시는 데이터베이스에 저장되어 있는 데이터를 단순히 복사해 온 값입니다. 만약 데이터가 변경될 때마다 데이터베이스에만 업데이트되어 캐시에는 변경된 값이 반영되지 않는다면 데이터 간 불일치가 일어납니다. 이러한 것을 **캐시 불일치(Cache Inconsistency)** 라고 합니다.

#### 1. **Write Through**

![cache-write-through](https://image.toast.com/aaaadh/real/2020/techblog/2%287%29.png)

이 방식은 **데이터베이스에 업데이트할 때마다 매번 캐시에도 데이터를 함께 업데이트**시키는 방식으로 동작합니다.

**장점:**
- 캐시는 항상 최신 데이터를 가지고 있습니다.
- **강한 일관성(Strong Consistency)** 을 보장합니다.

**단점:**
- 데이터가 매번 2개의 저장소에 저장되어야 하기 때문에 **쓰기 지연시간이 증가**할 수 있습니다.
- 다시 사용되지 않을 데이터에도 적용될 수 있어 **불필요한 캐시 저장**이 발생할 수 있습니다.

따라서 이 방식을 사용할 경우에는 데이터를 저장할 때 **적절한 만료 시간(TTL)** 을 사용할 것이 권장됩니다.

```redis-cli
# Write Through 예시
SET user:123 "updated_data" EX 3600  # 1시간 TTL 설정
```

#### 2. **Cache Invalidation**

이 방식은 **데이터베이스에 값을 업데이트할 때마다 캐시에서는 해당 데이터를 삭제**하는 전략입니다.

**장점:**
- 저장소에서 특정 데이터를 삭제하는 것이 새로운 데이터를 저장하는 것보다 **훨씬 적은 리소스**를 사용합니다.
- Write Through 방식의 단점을 보완한 방식입니다.

**단점:**
- 다음 읽기 요청 시 **캐시 미스가 발생**하여 데이터베이스에서 데이터를 다시 가져와야 합니다.

```redis-cli
# Cache Invalidation 예시
DEL user:123  # 캐시에서 삭제
```

#### 3. **Write Behind (Write Back)**

**쓰기가 빈번하게 발생하는 서비스**라면 Write Behind 방식을 고려해볼 수 있습니다. 대량의 쓰기 작업이 발생하면 이는 많은 디스크 I/O를 유발해 성능 저하가 발생할 수 있습니다.

**동작 방식:**
1. 먼저 데이터를 빠르게 접근할 수 있는 **캐시에 업데이트**
2. 이후에는 **건수나 특정 시간 간격**에 따라 **비동기적으로 데이터베이스에 업데이트**

**사용 사례:**
- **YouTube와 같은 스트리밍 서비스의 좋아요 수**는 매번 실시간 집계가 필요하지 않습니다.
- 좋아요를 누른 데이터를 우선 Redis에 저장한 뒤에 **5분 간격**으로 집계해 데이터베이스에 저장

**장점:**
- **높은 쓰기 성능**을 제공합니다.
- 데이터베이스의 **I/O 부하를 크게 감소**시킵니다.

**단점:**
- 캐시에 문제가 생기면 **아직 동기화되지 않은 데이터가 손실**될 수 있습니다.

```redis-cli
# Write Behind 예시 - 좋아요 카운팅
HINCRBY video:12345:stats likes 1
HINCRBY video:12345:stats views 1
```

![cache-write-strategies](https://storage.googleapis.com/download/storage/v1/b/designgurus-prod.appspot.com/o/docImages%2F641247a8900cc7b447191e60%2Fimg:bd73a18-ce51-f873-05f6-ee500b3d15.svg?generation=1678920001098651&alt=media)

### **캐시에서의 데이터 흐름**

기본적으로 캐시는 **데이터 스토어가 가진 데이터 중 사용자가 자주 사용할 만한 데이터**를 가져와서 임시로 저장하는 저장소입니다. 따라서 데이터 스토어보다 적은 양을 보관하는 **데이터베이스의 서브셋(Subset)** 이라고 볼 수 있습니다. Redis는 특히 **메모리에 모든 데이터를 저장**하며 기본적으로 데이터베이스보다 적은 양의 데이터를 보관할 수밖에 없습니다.

따라서 **일정 양의 데이터를 유지**해야 하며 계속해서 새로운 데이터가 저장되고 기존 데이터는 삭제될 수 있도록 관리되어야 합니다. 따라서 캐시로 Redis를 사용할 때에는 데이터를 저장함과 동시에 **적절한 시간의 TTL값을 지정**하는 것이 좋습니다.

**키에 만료시간을 지정하는 예제:**
```redis-cli
SET user:123 "user_data"
-> "OK"
EXPIRE user:123 60
-> (integer) 1
TTL user:123
-> (integer) 58

# 또는 SET과 동시에 TTL 설정
SET user:123 "user_data" EX 60
-> "OK"
```

#### **Redis의 키 만료 처리 방식**

Redis에서 키가 만료되었다고 해서 메모리에서 바로 삭제되는 것이 아닙니다. 키는 **passive**와 **active** 방식 두 가지로 작동됩니다.

**Passive 방식:**
- 클라이언트가 키에 접근하고자 할 때 키가 만료되었다면 **메모리에서 수동적으로 삭제**합니다.
- **지연 삭제(Lazy Deletion)** 방식입니다.

**Active 방식:**
- TTL 값이 있는 키 중 **20개를 랜덤하게 선택**하여 만료된 키를 모두 메모리에서 삭제합니다.
- 만약 **25% 이상의 키가 삭제**되었다면 다시 20개의 키를 랜덤하게 선택하여 확인합니다.
- 그렇지 않다면 선택된 20개의 키 집합에서 다시 확인합니다.
- 이러한 과정을 **1초에 10번** 수행합니다.
  
### **메모리 관리와 maxmemory-policy 설정**

키에 만료시간을 설정해 데이터가 자동으로 삭제되도록 함으로써 데이터의 수명을 관리할 수 있습니다. 하지만 Redis의 메모리는 제한적이기 때문에 **모든 키에 만료시간을 설정하더라도** 너무 많은 키가 저장되면 **메모리가 가득 차는 상황**이 발생할 수 있습니다. 

이러한 상황에서 Redis는 메모리 용량을 초과하는 양의 데이터가 저장되면 **내부 정책을 통해서 어떤 키를 삭제할지 결정**합니다.

**주요 설정값:**
- **maxmemory**: 데이터의 최대 저장 용량
- **maxmemory-policy**: 초과 용량 처리 방식

#### **Noeviction**

**기본값**은 `noeviction`입니다. 이는 **임의로 Redis가 데이터를 삭제하지 않고 에러를 반환**하는 설정입니다.

**특징:**
- 메모리가 가득 찰 경우 **새로운 쓰기 명령에 대해 에러를 반환**
- 관리자가 Redis의 데이터를 직접 삭제해야 함
- **캐시 용도로는 권장하지 않는 설정값**

```redis-cli
# 메모리가 가득 찬 상태에서 새로운 데이터 저장 시도
SET new_key "new_value"
-> (error) OOM command not allowed when used memory > 'maxmemory'
```

#### **LRU Eviction**

**LRU(Least Recently Used)** eviction 방식이란 Redis에 데이터가 가득 찼을 때 **가장 최근에 사용되지 않은 데이터부터 삭제**하는 정책입니다. **최근에 접근되지 않는 데이터는 나중에도 접근될 가능성이 낮을 것**이라는 가정을 전제로 합니다.

**1. volatile-lru**
- **TTL이 설정된 키들 중에서만** LRU 알고리즘을 적용하여 삭제
- 만료시간이 설정된 키가 없다면 **삭제하지 않고 에러 반환**

**2. allkeys-lru**
- **모든 키에 대해** LRU 알고리즘을 적용하여 삭제
- **캐시로 사용할 때 가장 일반적으로 권장되는 설정**

```redis-cli
# LRU 정책 설정
CONFIG SET maxmemory-policy allkeys-lru
```

#### **LFU Eviction**

**LFU(Least Frequently Used)** eviction 방식은 **가장 적게 사용된 데이터부터 삭제**하는 정책입니다. 접근 빈도가 낮은 데이터를 우선적으로 삭제합니다.

**1. volatile-lfu**
- **TTL이 설정된 키들 중에서만** LFU 알고리즘을 적용

**2. allkeys-lfu**
- **모든 키에 대해** LFU 알고리즘을 적용
- **장기간 운영되는 캐시에서 유용**

```redis-cli
# LFU 정책 설정
CONFIG SET maxmemory-policy allkeys-lfu
```

#### **Random Eviction**

이 방법은 **랜덤으로 데이터를 삭제**하기 때문에 예측 불가능함을 유발할 수 있습니다. Redis는 **근사 알고리즘(Approximation Algorithm)** 을 사용하기 때문에 LFU, LRU 데이터를 찾는 데에 큰 리소스를 사용하지 않습니다. 따라서 **굳이 Redis의 부하를 줄이기 위해서 이 옵션을 사용하는 것은 권장되지 않습니다**.

**1. volatile-random**
- TTL이 설정된 키들 중에서 랜덤하게 삭제

**2. allkeys-random**
- 모든 키 중에서 랜덤하게 삭제

#### **volatile-ttl**

이 방식은 **TTL이 설정된 키들 중에서 만료 시간이 가장 짧은(가장 빨리 만료될) 키를 삭제**합니다. 

**특징:**
- **근사 알고리즘**을 사용하기 때문에 모든 키를 스캔하면서 비교하지 않아도 됩니다.
- **간단하게 키를 찾아내어 삭제**할 수 있습니다.
- TTL이 설정된 키가 없다면 삭제하지 않고 에러를 반환합니다.

```redis-cli
# volatile-ttl 정책 설정
CONFIG SET maxmemory-policy volatile-ttl

# TTL 확인
TTL key1  # 30초 남음
TTL key2  # 10초 남음  <- 이 키가 먼저 삭제됨
```

**권장 설정:**
- **일반적인 캐시 용도**: `allkeys-lru`
- **접근 패턴이 일정한 환경**: `allkeys-lfu`
- **TTL 기반 관리**: `volatile-ttl`

### **캐시 스탬피드 현상 (Cache Stampede)**

Redis를 캐시로 활용할 때에 모든 키에 대해 **만료 시간을 설정하는 것은 권장**되지만, **대규모 트래픽 환경**에서는 만료 시간을 어떻게 설정하느냐에 따라 **캐시 스탬피드**와 같은 예상치 못한 문제 상황이 발생할 수 있습니다.

![cache-stampede](https://blog.kakaocdn.net/dn/TEPdU/btsMaybhMmW/FuoPYM3mlzLvfnRBA3p9n0/img.png)

**캐시 스탬피드란?**
- **인기 있는 캐시 키가 만료되는 순간**, 해당 데이터에 대한 **수많은 요청이 동시에 데이터베이스로 몰리는 현상**
- 캐시가 없는 상태에서 **모든 요청이 데이터베이스를 직접 호출**
- 데이터베이스에 **순간적으로 엄청난 부하**가 발생

**문제 상황 예시:**
1. 인기 상품 정보 캐시가 **정확히 오후 2시에 만료**
2. **수천 명의 사용자**가 동시에 해당 상품 페이지에 접근
3. 모든 요청이 캐시 미스 발생으로 **데이터베이스로 몰림**
4. 데이터베이스 **응답 시간 급증** 또는 **서버 다운**

#### **해결 방법**

#### **1. 적절한 만료 시간 설정 (Jitter 적용)**

**동일한 TTL 값을 사용하지 않고**, 각 키마다 **약간의 랜덤한 시간을 추가**하여 만료 시점을 분산시킵니다.

```redis-cli
# 기존 방식 (위험) - 모든 키가 동시에 만료
SET product:123 "data" EX 3600  # 정확히 1시간 후 만료

# 개선된 방식 - 랜덤 지터 적용
SET product:123 "data" EX 3720  # 3600 + (0~240초 랜덤)
SET product:124 "data" EX 3680  # 3600 + (0~240초 랜덤)
SET product:125 "data" EX 3790  # 3600 + (0~240초 랜덤)
```

#### **2. 선 계산 (Pre-computation)**

**캐시가 만료되기 전에 미리 새로운 데이터를 계산**하여 캐시를 갱신하는 방법입니다.

**구현 방법:**
- 실제 TTL보다 **짧은 논리적 TTL을 함께 저장**
- 논리적 TTL이 만료되면 **백그라운드에서 데이터를 갱신**
- 실제 캐시는 계속 서비스하면서 **무중단으로 갱신**

```redis-cli
# 데이터와 함께 논리적 만료시간도 저장
HSET product:123 data "actual_product_data" logical_expire "1640995200"
EXPIRE product:123 7200  # 실제 TTL은 2시간

# 논리적 만료시간 확인 후 갱신 여부 결정
HGET product:123 logical_expire
```

#### **3. PER 알고리즘 (Probabilistic Early Refresh)**

**통계적 접근법**을 사용하여 캐시가 만료되기 전에 **확률적으로 갱신**하는 방법입니다.

**동작 원리:**
- 캐시 조회 시마다 **일정 확률로 갱신 여부를 결정**
- TTL이 짧아질수록 **갱신 확률이 높아짐**
- **여러 요청 중 하나만** 실제 갱신을 수행

#### **4. 분산 락 (Distributed Lock) 사용**

**하나의 요청만 데이터베이스에 접근**하도록 제어하는 방법입니다.

**각 방법의 특징:**

| 방법 | 장점 | 단점 | 적용 상황 |
|------|------|------|-----------|
| **Jitter** | 구현 간단, 효과적 | 근본적 해결책은 아님 | 모든 캐시 환경 |
| **선 계산** | 무중단 서비스 가능 | 복잡한 구현, 추가 리소스 | 계산 비용이 높은 데이터 |
| **PER** | 자동화된 갱신 | 확률 기반의 불확실성 | 중간 규모 트래픽 |
| **분산 락** | 정확한 제어 | 성능 오버헤드 | 고중요도 데이터 |

### **세션 저장소로서의 Redis**

웹 애플리케이션에서 **사용자 세션 정보를 저장**하기 위해 Redis를 활용하는 것은 매우 일반적이고 효과적인 방법입니다. 특히 **마이크로서비스 아키텍처**나 **로드 밸런싱 환경**에서 Redis 세션 저장소는 필수적입니다.

#### **기존 세션 저장 방식의 문제점**

**1. 메모리 기반 세션 (In-Memory Session)**
```java
// 서버 메모리에 세션 저장
HttpSession session = request.getSession();
session.setAttribute("userId", "12345");
```

**문제점:**
- **서버 재시작 시 모든 세션 데이터 손실**
- **로드 밸런싱 환경에서 세션 공유 불가** (Sticky Session 필요)
- **스케일 아웃 시 세션 동기화 문제**

**2. 데이터베이스 기반 세션**
```sql
CREATE TABLE sessions (
    session_id VARCHAR(255) PRIMARY KEY,
    user_id VARCHAR(255),
    data TEXT,
    created_at TIMESTAMP,
    expires_at TIMESTAMP
);
```

**문제점:**
- **읽기/쓰기 성능이 상대적으로 느림**
- **데이터베이스 부하 증가**
- **세션 만료 처리의 복잡성**

#### **Redis 세션 저장소의 장점**

**1. 고성능**
- **메모리 기반 저장**으로 빠른 읽기/쓰기
- **O(1) 시간 복잡도**의 키-값 조회

**2. 분산 환경 지원**
- **여러 서버에서 동일한 세션 데이터 공유**
- 로드 밸런서의 **라운드 로빈 방식** 사용 가능

**3. 자동 만료 기능**
- **TTL을 이용한 자동 세션 만료**
- 별도의 배치 작업 불필요

**4. 데이터 구조 지원**
- **복잡한 세션 데이터**도 효율적으로 저장
- Hash, Set 등 다양한 자료구조 활용

#### **Redis 세션 구현 예시**

**1. 기본적인 세션 저장**
```redis-cli
# 세션 생성 (30분 TTL)
SETEX session:a1b2c3d4e5f6 1800 '{"userId":"12345","username":"john","role":"user"}'

# 세션 조회
GET session:a1b2c3d4e5f6

# 세션 갱신 (활동 시 TTL 연장)
EXPIRE session:a1b2c3d4e5f6 1800

# 세션 삭제 (로그아웃)
DEL session:a1b2c3d4e5f6
```

**2. Hash를 이용한 구조화된 세션**
```redis-cli
# 세션 데이터를 Hash로 저장
HSET session:a1b2c3d4e5f6 userId "12345"
HSET session:a1b2c3d4e5f6 username "john"
HSET session:a1b2c3d4e5f6 role "user"
HSET session:a1b2c3d4e5f6 lastAccess "1640995200"
EXPIRE session:a1b2c3d4e5f6 1800

# 특정 필드만 조회
HGET session:a1b2c3d4e5f6 userId

# 여러 필드 동시 조회
HMGET session:a1b2c3d4e5f6 userId username role

# 세션 전체 조회
HGETALL session:a1b2c3d4e5f6
```

#### **실제 구현 코드 예시**

**Spring Boot + Redis 세션 구현:**
```java
@Service
public class RedisSessionService {
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    private static final String SESSION_PREFIX = "session:";
    private static final int SESSION_TIMEOUT = 1800; // 30분
    
    // 세션 생성
    public String createSession(String userId, String username) {
        String sessionId = UUID.randomUUID().toString();
        String sessionKey = SESSION_PREFIX + sessionId;
        
        Map<String, Object> sessionData = new HashMap<>();
        sessionData.put("userId", userId);
        sessionData.put("username", username);
        sessionData.put("createdAt", System.currentTimeMillis());
        sessionData.put("lastAccess", System.currentTimeMillis());
        
        // Hash로 저장
        redisTemplate.opsForHash().putAll(sessionKey, sessionData);
        redisTemplate.expire(sessionKey, SESSION_TIMEOUT, TimeUnit.SECONDS);
        
        return sessionId;
    }
    
    // 세션 조회
    public Map<Object, Object> getSession(String sessionId) {
        String sessionKey = SESSION_PREFIX + sessionId;
        Map<Object, Object> sessionData = redisTemplate.opsForHash().entries(sessionKey);
        
        if (!sessionData.isEmpty()) {
            // 마지막 접근 시간 업데이트
            updateLastAccess(sessionId);
        }
        
        return sessionData;
    }
    
    // 세션 갱신
    public void updateLastAccess(String sessionId) {
        String sessionKey = SESSION_PREFIX + sessionId;
        
        redisTemplate.opsForHash().put(sessionKey, "lastAccess", System.currentTimeMillis());
        redisTemplate.expire(sessionKey, SESSION_TIMEOUT, TimeUnit.SECONDS);
    }
    
    // 세션 삭제
    public void deleteSession(String sessionId) {
        String sessionKey = SESSION_PREFIX + sessionId;
        redisTemplate.delete(sessionKey);
    }
    
    // 사용자의 모든 세션 조회 (다중 로그인 관리)
    public Set<String> getUserSessions(String userId) {
        String pattern = SESSION_PREFIX + "*";
        Set<String> sessionKeys = redisTemplate.keys(pattern);
        Set<String> userSessions = new HashSet<>();
        
        for (String sessionKey : sessionKeys) {
            Object storedUserId = redisTemplate.opsForHash().get(sessionKey, "userId");
            if (userId.equals(storedUserId)) {
                userSessions.add(sessionKey.replace(SESSION_PREFIX, ""));
            }
        }
        
        return userSessions;
    }
}
```

**Spring Security 통합:**
```java
@Configuration
@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 1800)
public class RedisSessionConfig {
    
    @Bean
    public LettuceConnectionFactory redisConnectionFactory() {
        return new LettuceConnectionFactory(
            new RedisStandaloneConfiguration("localhost", 6379)
        );
    }
}
```

#### **세션 보안 고려사항**

**1. 세션 ID 보안**
```java
// 안전한 세션 ID 생성
public String generateSecureSessionId() {
    SecureRandom random = new SecureRandom();
    byte[] bytes = new byte[32];
    random.nextBytes(bytes);
    return Base64.getUrlEncoder().withoutPadding().encodeToString(bytes);
}
```

**2. 세션 고정 공격 방지**
```java
// 로그인 성공 시 새로운 세션 ID 발급
public void regenerateSessionId(String oldSessionId, String userId) {
    // 기존 세션 데이터 백업
    Map<Object, Object> sessionData = getSession(oldSessionId);
    
    // 기존 세션 삭제
    deleteSession(oldSessionId);
    
    // 새로운 세션 생성
    String newSessionId = createSession(userId, (String) sessionData.get("username"));
    
    return newSessionId;
}
```

**3. 세션 데이터 암호화**
```java
@Component
public class EncryptedRedisTemplate {
    
    @Autowired
    private AESUtil aesUtil;
    
    public void setSecureData(String key, Object data) {
        String encryptedData = aesUtil.encrypt(JSON.toJSONString(data));
        redisTemplate.opsForValue().set(key, encryptedData);
    }
    
    public Object getSecureData(String key, Class<?> clazz) {
        String encryptedData = (String) redisTemplate.opsForValue().get(key);
        if (encryptedData != null) {
            String decryptedData = aesUtil.decrypt(encryptedData);
            return JSON.parseObject(decryptedData, clazz);
        }
        return null;
    }
}
```

#### **성능 최적화 팁**

**1. 세션 데이터 최소화**
```java
// 필요한 정보만 세션에 저장
Map<String, Object> sessionData = new HashMap<>();
sessionData.put("userId", userId);           // 필수
sessionData.put("role", userRole);           // 권한 체크용
sessionData.put("lastAccess", timestamp);    // 활동 추적용
// sessionData.put("userProfile", profile);  // 불필요 - DB에서 조회
```

**2. Pipeline 사용**
```java
// 여러 세션 작업을 파이프라인으로 처리
public void batchUpdateSessions(List<String> sessionIds) {
    redisTemplate.executePipelined(new RedisCallback<Object>() {
        @Override
        public Object doInRedis(RedisConnection connection) {
            for (String sessionId : sessionIds) {
                String key = SESSION_PREFIX + sessionId;
                connection.hSet(key.getBytes(), "lastAccess".getBytes(), 
                               String.valueOf(System.currentTimeMillis()).getBytes());
                connection.expire(key.getBytes(), SESSION_TIMEOUT);
            }
            return null;
        }
    });
}
```

**Redis 세션 저장소는 현대적인 웹 애플리케이션의 필수 구성 요소**로, **고성능**, **확장성**, **신뢰성**을 모두 제공하는 효과적인 솔루션입니다.